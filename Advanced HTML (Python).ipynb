{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced HTML data collection\n",
    "\n",
    "Increasingly, websites cannot be analysed just through web scraping -- they include components which are rendered only on the browser.\n",
    "This is both a challenge and an opportunity, as often such webpages may pull content from internal grey APIs as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium\n",
    "\n",
    "[Selenium](https://www.selenium.dev/) is a tool which allows executing content on the website, rendering it like a website would do.\n",
    "It is possible to get the full _rendered_ HTML and use other tools on that, such as BeautifulSoup; or then use its inbuild tools to collect data and navigate on the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening a new web browser\n",
    "\n",
    "Selenium is aimed for automated testing of different browsers.\n",
    "Therefore, you can open different browsers through [webdrivers](https://www.selenium.dev/documentation/webdriver/).\n",
    "Variable `page_source` includes HTML for the full website, and [`find_element` function](https://www.selenium.dev/documentation/webdriver/elements/locators/) can be used to identify elements through tag name, class name, id or xpath.\n",
    "\n",
    "It is also possible to [interact](https://www.selenium.dev/documentation/webdriver/elements/interactions/) with the webpage, such as click elements, press keys or [produce action chains](https://www.selenium.dev/documentation/webdriver/actions_api/). [Selenium IDE](https://www.selenium.dev/selenium-ide/) helps with these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"http://www.helsinki.fi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_content = driver.page_source\n",
    "\n",
    "parsed = BeautifulSoup( html_content, 'lxml' )\n",
    "\n",
    "for image in  parsed.find_all('img'):\n",
    "    print( image )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in driver.find_elements(By.TAG_NAME, 'img'):\n",
    "    print( image.get_attribute(\"src\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in driver.find_elements(By.TAG_NAME, 'a'):\n",
    "    print( link.get_attribute(\"href\"), link.text )\n",
    "    print( link.get_attribute('outerHTML') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element( By.XPATH, \"/html/body/div[2]/div/hy-main/div/div/div/article/hy-hero-carousel/div/div/div[1]/div[1]/div/div[1]/hy-cta-button/span/a/span[1]\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stop the execution\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. Find all links on Yle.fi main page. What amount of them starts with http?\n",
    "1. Find all images on Yle.fi and print their URLs\n",
    "1. Go through all Finnish university web frontpages. Which of them have have a link to (a) Facebook, (b) TikTok or (c) X?\n",
    "1. Go through all Finnish university web frontpages. Collect and download all images from them.\n",
    "1. Extract the text of a single article on Yle.fi\n",
    "1. Extract the text of a single article on HS.fi\n",
    "1. Extract the text of a single news article on Helsinki.fi\n",
    "1. Extract the text of a single news article on Aamulehti.fi\n",
    "1. Extract the text of a single news article on BBC.com\n",
    "1. Extract the text of a single news article on New York Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grey APIs\n",
    "\n",
    "Websites which allow unlimited scrolling often have some kind of API which allow website to \"pull\" new content.\n",
    "It is possible to use these APIs directly, but sometimes they require tricks -- such as setting cookies, executing the command on a web broser as logged in user, using a spesific application key etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "data = requests.get(\"https://ca.api.yle.fi/v1/graphql?app_id=ukko_prod&app_key=12150df3a0c8844d37c520235bf7c5d4&query=query+tuoreimmatMostRecentUutisetAndUrheiluQuery+($limit:Int!$exclude:Exclude!$publishedBefore:String+$fields:ArticleFields+%3DHEADLINE)%7Btuoreimmat:+mostRecentUutisetAndUrheiluMainNews+(+limit:$limit+exclude:$exclude+publishedBefore:$publishedBefore+fields:$fields+)%7Bitems%7Bid+title+fullUrl+lead+publisher%7Bname%7Dsubjects%7B...conceptFields%7DdatePublished+format+headline%7Bfull+short+image%7B...on+ImageBlock%7B...listItemImageBlockFields%7D%7Dvideo%7B...on+VideoBlock%7Bid+image%7B...listItemImageBlockFields%7D%7D%7Daudio%7B...on+AudioBlock%7Bid+image%7B...listItemImageBlockFields%7D%7D%7D%7DmainMedia%7Btype:__typename...on+ImageBlock%7B...listItemImageBlockFields%7D...on+AudioBlock%7Bid+image%7B...listItemImageBlockFields%7D%7D...on+VideoBlock%7Bid+offsetSeconds+image%7B...listItemImageBlockFields%7D%7D%7Dtopic%7Bid+isHidden+isLocked+acceptedCommentsCount%7D%7D%7D%7Dfragment+conceptFields+on+Concept%7Bid+alternativeIds+title%7Bfi+sv+se+en+uk+ru%7D%7Dfragment+listItemImageBlockFields+on+ImageBlock%7Bid+alt+version+blurhash+crops%7Baspect+coordinates%7Bheight+width+x+y%7D%7D%7D&variables=%7B%22limit%22:21,%22exclude%22:%7B%22properties%22:[%22importance:low%22,%22automaticListHint:never%22,%22automaticListHint:no-recently%22],%22journalisticStyle%22:[%22non_journalistic_content%22],%22coverage%22:%22LOCAL%22%7D,%22publishedBefore%22:%222024-08-22T03:15:46%2B0300%22%7D\").json()\n",
    "\n",
    "print( data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "* Comments from YLE\n",
    "* Comments for HS\n",
    "* Voluntary: Collect Tiktok vidoes on cats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tricks of the trade\n",
    "\n",
    "Sometimes websites try to block data collection.\n",
    "There are some techniques you can use:\n",
    "\n",
    "* request headers: ensure your requests looks like it is a real web browser\n",
    "* cookies: collect and use the cookies provided by the services and sent them back to them\n",
    "* wait: sometimes services request you to wait for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
